---
title: "Working From the Bara et al. Example"
author: "Will Lowe"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{bara-et-al}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

## Set Chunk Options

```{r warning=FALSE, message=FALSE}
library(knitr)
knitr::opts_chunk$set(comment = "")
```

## Prepare
```{r, include = FALSE}
library(topicdict)
library(purrr)
library(tidyr)
library(dplyr)
library(ggplot2)
```

```{r}
library(quanteda)
data(corpus_bara_para)
corp <- corpus_subset(corpus_bara_para, 
                      speaker != "Mrs Anne Kerr")
```

We choose seeds from an existing dictionary (it's in the data folder)
```{r}
file <- system.file("extdata", "bara-et-al.ykd", package = "topicdict")
ddict <- dictionary(file = file)
ddict
ddict_words <- as.vector(unlist(ddict))
```
It would be a bad idea to remove gendered pronouns as stop words because 
of the debate topic, so we don't do that
```{r}
estops <- stopwords("english") # re-gendered stopwords
# stops minus some gender words
stops <- estops[!(estops %in% c("her", "his", "he", "she", "their", "our"))]
```
Now we make a document term matrix and take a copy that's tf-idf transformed.
we'll use that to choose informative words.
```{r}
dtm_orig <- dfm(corp, remove=stops, 
                remove_numbers = TRUE, 
                remove_punct = TRUE,
                remove_symbols = TRUE, 
                remove_separators = TRUE,
                remove_hyphens = TRUE)
tfidf_dtm_orig <- tfidf(dtm_orig)
```

The 50 most informative words in thus corpus according to tf-idf score
```{r}
sort(colMeans(tfidf_dtm_orig), decreasing = TRUE)[1:50]

informative_wds <- data.frame(tfidf=colMeans(tfidf_dtm_orig))
informative_wds <- informative_wds[order(informative_wds$tfidf, 
                                         decreasing = TRUE),, drop=FALSE]
```
Next we'll construct the paper's topic counts using their dictionary.
This is what they think the correct, person summed, topic counts ought to be
for their dictionary topics.
```{r}
topics_orig_dict <- dfm(corp, remove = stops, 
                              remove_numbers = TRUE, 
                              remove_punct = TRUE,
                              remove_symbols = TRUE, 
                              remove_separators = TRUE,
                              remove_hyphens = TRUE,
                              dictionary = ddict)
tt <- data.frame(topics_orig_dict, 
                 speaker = docvars(corp, "speaker")) 
colnames(tt) <- unlist(gsub("incoming.txt.", "", colnames(tt)))
tts <- summarise_at(group_by(tt, speaker), 
                    vars(advocacy, legal, medical,
                         moral, procedural, social),
                     sum)
tts <- as.data.frame(tts)
tt_prop <- data.frame(tts[,2:7] / rowSums(tts[,2:7]), 
                      row.names = tts$speaker)
tt_prop
```

Now pick the top 10 tfidf-informative words from each of the dictionary 
categories as seeds, and write these to a file
```{r}
seeds <- lapply(ddict$incoming.txt, 
       function(x){ 
         candidates <- intersect(rownames(informative_wds), x)
         inf <- informative_wds[candidates,,drop=FALSE]
         rownames(inf)[order(inf$tfidf, decreasing = TRUE)[1:10]]
       })
lines <- as.vector(apply(t(as.data.frame(seeds)), 1, 
                         paste, collapse = " "))
writeLines(c("##", lines), con = file("./bara_seeds.txt"))
```

The next bit of code writes out each text to a file with a suitable name in 
folder `bara_paras`
```{r}
tt <- tokens(corp, remove_numbers = TRUE, 
                   remove_punct = TRUE,
                   remove_symbols = TRUE, 
                   remove_separators = TRUE,
                   remove_hyphens = TRUE)
tt <- lapply(tt, function(x) { 
  x <- char_tolower(x)
  paste(x[!(x %in% stops)], collapse=" ") 
})
names(tt) <- gsub(" ", "_", 
                  paste0(make.unique(docvars(corp, "speaker")), ".txt"))
if (!dir.exists("bara_paras"))
  dir.create("bara_paras")
devnull <- lapply(names(tt), function(x){ 
  writeLines(tt[[x]], con=file.path("bara_paras", x))
})

## assign these document names later
docnames <- names(tt)
```

OK, let's run a model
```{r}
res <- seededlda(data_folder_path = "bara_paras",
                 seed_csv_path = "bara_seeds.txt",
                 num_regular_topic = 1,
                 iter_num = 100,
                 show_words_num = 20,
                 full_output = TRUE,
                 rand_seed = 919)
```
Now let's bundle up the posterior and use the new functions on it
```{r}
post <- posterior(res)
# add document names
post <- set_doc_names(post, docnames)
top_terms(post)
# suggest some names for topics
tnames <- suggest_topic_names(post, n = 4)
tnames
# assign them
post <- set_topic_names(post, tnames)
# top 2 topics in each document
head(top_topics(post, 2))
# and now the document that the most of each topic
top_docs(post)
# we know how people voted
unique(docvars(corp))
# so it's not so surprising that the child related topic
# is represented by the dissenters
top_docs(post, 15)
```

What difference does it make if there are more than one non-seeded topics?

To make things crash, remove `eval=FALSE` from the following code chunks:
```{r, eval = FALSE}
res5 <- seededlda(data_folder_path = "bara_paras",
                  seed_csv_path = "bara_seeds.txt",
                  num_regular_topic = 3,
                  iter_num = 100,
                  show_words_num = 20,
                  full_output = TRUE,
                  rand_seed = 919)
```

```{r, eval = FALSE}
post <- posterior(res)
# add document names
post <- set_doc_names(post, docnames)
top_terms(post)
```

How does this compare to regular LDA?
```{r, eval = FALSE}
library(topicmodels)
dtm_lda <- as.DocumentTermMatrix(dtm_orig)
```



