---
title: "Election Platforms"
author: "Will Lowe"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{election-platforms}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = ""
)

library(topicdict)
library(quanteda)
library(ca)
library(dplyr)
library(ggplot2)
theme_set(theme_minimal())
```

```{r}
dictfile <- system.file("extdata/laver-garry-ajps.ykd", package="topicdict")
# We'll use just the economics sections of this dictionary
dict <- dictionary(file = dictfile)[["Laver and Garry"]][["State in Economy"]]
dict$Neut <- NULL # not interested in this category! Just Pro / Con
# load the corpus
data("corpus_uk_platforms")
```

Preprocess the dictionary to expand the wildcards and filter out low frequency
terms
```{r}
new_dict <- preprocess_dictionary(dict, corpus_uk_platforms, min.freq = 5,
                                  remove = stopwords(), remove_numbers = TRUE, 
                                  remove_punct = TRUE, remove_symbols = TRUE,
                                  remove_separators = TRUE, remove_hyphens = FALSE)
cbind(old = lapply(dict, length),
      new = lapply(new_dict, length))
```

Laver and Garry compute a left-right measure for platform i using a dictionary 
with 'left' words $\{L\}$ and 'right' words $\{R\}$ as
$$
POS_i = \frac{R_i - L_i}{R_i + L_i}
$$
where 
\begin{align*}
R_i =& \sum^{N_i}_j I[w_j \in \{L\} \\
L_i =& \sum^{N_i}_j I[w_j \in \{R\}.
\end{align*}

We'll fit the full data set and then compare the measure from the dictionary
to the measure from topicdict counts.

```{r}
dtm_orig <- dfm(corpus_uk_platforms, 
                dictionary = new_dict,
                remove = stopwords(), remove_numbers = TRUE, 
                remove_punct = TRUE, remove_symbols = TRUE,
                remove_separators = TRUE, remove_hyphens = FALSE)
res <- data.frame(dtm_orig)
ca_res <- data.frame(docvars(dtm_orig), 
                     POS = (res$Con - res$Pro) / (res$Con + res$Pro),
                     logitPOS = log(res$Con) - log(res$Pro))
```
One substantively sensible way to plot this 'gold standard' is as time series of 
the main parties
```{r, fig.width=15, fig.height=10}
partyabbrev <- c("Con", "Lib", "Lab", "LD", "LibSDP")
ca_subset <- subset(ca_res, party %in% partyabbrev)
ggplot(ca_subset, aes(date, POS, color = party)) + 
  geom_line() + 
  geom_point() + 
  geom_vline(xintercept = c(1992, 1997), alpha = 0.1, size = 5 ) + 
  scale_color_manual(values = c("blue", "red", "orange", "orange", "orange")) +
  coord_flip() 
```

The gray bars indicate 1992: the election whose platforms were used to write the 
dictionary, and 1997: the election whose platforms POS values 
were used to show off the method in Laver and Garry (2000).
Substantively the interesting thing about 1997 is (supposed to be) that the 
Liberal Democrat (LD) and Labour Party (Lab) positions on the economy switch.

Notice that the results are consistent with overfitting to the 1992 platforms 
and subsequent measurement error attenuation in the subsequent (and previous) 
POS values.

There is rather variable overlap of the words in the dictionary with
words in the party platforms.  Curiously these seem to be very 1979 
election sorts of words (when Thatcher came to power and moved political
rhetoric in a much more neoliberal direction).
```{r, fig.width=15, fig.height=10}
dtm_over <- dfm(corpus_uk_platforms, 
                remove = stopwords(), remove_numbers = TRUE, 
                remove_punct = TRUE, remove_symbols = TRUE,
                remove_separators = TRUE, remove_hyphens = FALSE)

pro_prop <- apply(dfm_select(dtm_over, pattern = unlist(new_dict$Pro), selection = "keep", valuetype = "fixed"), 1, function(x){ sum(x != 0.0) / length(x) })
con_prop <- apply(dfm_select(dtm_over, pattern = unlist(new_dict$Con), selection = "keep", valuetype = "fixed"), 1, function(x){ sum(x != 0.0) / length(x) })
prop_res <- data.frame(docvars(dtm_orig), 
                       pro = pro_prop, con = con_prop) %>% 
  tidyr::gather(pc, overlap, pro:con)
prop_res_subset <- subset(prop_res, party %in% partyabbrev)
ggplot(prop_res_subset, aes(date, overlap, color = pc)) + 
  geom_line() + 
  geom_point() + 
  geom_vline(xintercept = c(1992, 1997), alpha = 0.1, size = 5 ) + 
  ylim(0, 1) +
  ylab("Proportion of dictionary words appearing at least once in platform") +
  facet_grid(party ~ .)
```

For reference, here's what a regular count data scaling model would do with
the Con and Pro categories
```{r, fig.width=15, fig.height=10}
ggplot(ca_subset, aes(date, logitPOS, color = party)) + 
  geom_line() + 
  geom_point() + 
  geom_vline(xintercept = c(1992, 1997), alpha = 0.1, size = 5 ) + 
  scale_color_manual(values = c("blue", "red", "orange", "orange", "orange")) +
  coord_flip() 
```

and an even nicer version from straight word count scaling using only
the items in `new_dict`:
```{r, fig.width=15, fig.height=10}
dd <- dfm(corpus_uk_platforms, 
          remove = stopwords(), remove_numbers = TRUE, 
          remove_punct = TRUE, remove_symbols = TRUE,
          remove_separators = TRUE, remove_hyphens = FALSE)
dd <- dfm_select(dd, unlist(new_dict))  
dd <- dfm_trim(dd, min_count = 5, min_docfreq = 5)
mod <- ca::ca(as.matrix(dd))
ca_res$scaling1 <- mod$rowcoord[,1]
ca_res$scaling2 <- mod$rowcoord[,2]
ca_subset <- subset(ca_res, party %in% partyabbrev)

ggplot(ca_subset, aes(date, scaling1, color = party)) + 
  geom_line() + 
  geom_point() + 
  geom_vline(xintercept = c(1992, 1997), alpha = 0.1, size = 5 ) + 
  scale_color_manual(values = c("blue", "red", "orange", "orange", "orange")) +
  coord_flip() 
```

So now we fit a topicdict to see if we can 

1. recover the same result
2. fix the measurement error weirdness

First up. One extra topic:

```{r}
set.seed(1234)
mod <- topicdict_model(corpus_uk_platforms, dict = new_dict, 
                stopwords = stopwords(), remove_numbers = TRUE, 
                remove_punct = TRUE, remove_symbols = TRUE,
                remove_separators = TRUE, remove_hyphens = FALSE)
mod <- topicdict_train(mod, 340)
```

Not much overlap in words
```{r}
post <- posterior(mod)
top_terms(post, n = 50)
```
Now compute the measure and fold it into the old data
```{r}
th <- data.frame(post$theta)
th$doc_id <- rownames(th) # for merging
th$tdPOS <- (th[,'Con'] - th[,'Pro']) / (th[,'Con'] + th[,'Pro'])
together <- left_join(docvars(dtm_orig), th, by = "doc_id") %>%
  filter(party %in% partyabbrev)
```
and plot
```{r, fig.width=15, fig.height=10}
ggplot(together, aes(date, tdPOS, color = party)) + 
  geom_line() + 
  geom_point() + 
  geom_vline(xintercept = c(1992, 1997), alpha = 0.1, size = 5 ) + 
  scale_color_manual(values = c("blue", "red", "orange", "orange", "orange")) +
  coord_flip() 
```

Interestingly we do not really get so many seed words, but we *do* get two categories
whose proportions combine in the right way.  We do not see the 
position order reversal but we do see the Labour Party veering right in 1997.

The next steps are

1. A model with more spare categories to soak up non-economics topics
2. A restricted version that ignores platforms older than roughly the 1980s,
   which we'd expect to want for the usual reasons (pre / post Thatcher, 
   basically)

So now we fit a topicdict to see if we can 

1. recover the same result
2. fix the measurement error weirdness

```{r}
set.seed(1234)
post70s_corpus <- corpus_subset(corpus_uk_platforms, date > 1970)
mod <- topicdict_model(post70s_corpus, dict = new_dict, 
                stopwords = stopwords(), remove_numbers = TRUE, 
                remove_punct = TRUE, remove_symbols = TRUE,
                remove_separators = TRUE, remove_hyphens = FALSE)
mod <- topicdict_train(mod, 340)
```

Overlap in words?
```{r}
post <- posterior(mod)
top_terms(post, n = 50)
```
Now compute the measure again and fold it into the old data
```{r}
th <- data.frame(post$theta)
th$doc_id <- rownames(th) # for merging
th$modPOS <- (th[,'Con'] - th[,'Pro']) / (th[,'Con'] + th[,'Pro'])
together <- left_join(docvars(post70s_corpus), th, by = "doc_id") %>% 
  filter(party %in% partyabbrev)
```
and plot
```{r, fig.width=15, fig.height=10}
ggplot(together, aes(date, modPOS, color = party)) + 
  geom_line() + 
  geom_point() + 
  geom_vline(xintercept = c(1992, 1997), alpha = 0.1, size = 5 ) + 
  scale_color_manual(values = c("blue", "red", "orange", "orange", "orange")) +
  coord_flip() 
```

Let's now try with more spare categories
```{r}
set.seed(1234)
post70s_corpus <- corpus_subset(corpus_uk_platforms, date > 1970) 
mod <- topicdict_model(post70s_corpus, dict = new_dict, 
                stopwords = stopwords(), remove_numbers = TRUE, 
                remove_punct = TRUE, remove_symbols = TRUE,
                remove_separators = TRUE, remove_hyphens = FALSE,
                extra_k = 5)
mod <- topicdict_train(mod, 340)
```

Overlap in words?
```{r}
post <- posterior(mod)
top_terms(post, n = 50)
```
This is a sensible decomposition: the non-seeded topics are dominated by, 
in order

- Ireland: Ireland, Sinn Fein, peace, Unionist, agreement
- General politics: government, trade, labour, democracy, system, individual
- Wales: Wales, Plaid Cymru, welsh, england, parliament
- Scotland: Scotland, scottish, energy, Westminster, taxes
- Britain (as an entity, in contrast to Europe and foreigners): British, national, immigration, foreign, UKIP, traditional, control

Now compute the measure again and fold it into the old data.
This time with simple logit error bars to give a sense of the error
```{r}
th <- data.frame(post$theta)
th$doc_id <- rownames(th) # for merging
th$modPOS <- (th[,'Con'] - th[,'Pro']) / (th[,'Con'] + th[,'Pro'])
th$logitPOS <- log(th[,'Con']) - log(th[,'Pro'])
th$n <- summary(post70s_corpus)$Tokens
together <- left_join(docvars(post70s_corpus), th, by = "doc_id") %>% 
  filter(party %in% partyabbrev)
together$se <- sqrt(1 / (together$Con * together$n) + 
                    1 / (together$Pro * together$n))
together$ci.lower <- together$logitPOS - 2 * together$se
together$ci.upper <- together$logitPOS + 2 * together$se
# together$prop <- together$Con + together$Pro > 0.6
```
and plot
```{r, fig.width=15, fig.height=10}
ggplot(together, aes(date, logitPOS, color = party)) + 
  geom_line() + 
  geom_point() + #aes(size = prop)) + 
  geom_vline(xintercept = c(1992, 1997), alpha = 0.1, size = 5 ) + 
  geom_ribbon(aes(x = date, ymin = ci.lower, ymax = ci.upper, 
                  fill = party, color = NA), 
              alpha = 0.25) +
  scale_color_manual(values = c("blue", "red", "orange", "orange", "orange")) +
  scale_fill_manual(values = c("blue", "red", "orange", "orange", "orange")) +
  coord_flip() 
```

Lo and behold, our 92-97 flip on the economic axis is back.

Even more categories?
```{r}
set.seed(1234)
mod <- topicdict_model(post70s_corpus, dict = new_dict, 
                stopwords = stopwords(), remove_numbers = TRUE, 
                remove_punct = TRUE, remove_symbols = TRUE,
                remove_separators = TRUE, remove_hyphens = FALSE,
                extra_k = 10)
mod <- topicdict_train(mod, 340)
```

Overlap in words?
```{r}
post <- posterior(mod)
top_terms(post, n = 50)
```

Categories are a bit mushier.  Not surprising given the lack of data.
```{r}
th <- data.frame(post$theta)
th$doc_id <- rownames(th) # for merging
th$modPOS <- (th[,'Con'] - th[,'Pro']) / (th[,'Con'] + th[,'Pro'])
th$logitPOS <- log(th[,'Con']) - log(th[,'Pro'])
th$n <- summary(post70s_corpus)$Tokens
together <- left_join(docvars(post70s_corpus), th, by = "doc_id") %>% 
  filter(party %in% partyabbrev)
together$se <- sqrt(1 / (together$Con * together$n) + 
                    1 / (together$Pro * together$n))
together$ci.lower <- together$logitPOS - 2 * together$se
together$ci.upper <- together$logitPOS + 2 * together$se
# together$prop <- together$Con + together$Pro > 0.6
```
and plot
```{r, fig.width=15, fig.height=10}
ggplot(together, aes(date, logitPOS, color = party)) + 
  geom_line() + 
  geom_point() + #aes(size = prop)) + 
  geom_vline(xintercept = c(1992, 1997), alpha = 0.1, size = 5 ) + 
  geom_ribbon(aes(x = date, ymin = ci.lower, ymax = ci.upper, 
                  fill = party, color = NA), 
              alpha = 0.25) +
  scale_color_manual(values = c("blue", "red", "orange", "orange", "orange")) +
  scale_fill_manual(values = c("blue", "red", "orange", "orange", "orange")) +
  coord_flip() 
```

What's going on with the other dimensions?  Time for a correspondence analysis:
```{r, fig.width=15, fig.height=15}
vv <- together %>% 
  mutate_at(vars(Pro:T_10), function(x){ x * .$n }) %>% 
  select(Pro:T_10) %>% 
  round 
rownames(vv) <- paste(together$party, together$date)
colnames(vv) <- c("pro", "con", "scotland", "eu", "ireland", "??", "industry", "capitalism", "wales", "community", "nation", "lib/green")
plot(ca(vv))
```

