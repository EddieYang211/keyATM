---
title: "Consequences of differing confidence in the seed words in Bara et al."
author: "Will Lowe"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{dictionary-confidence}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---


```{r warning=FALSE, message=FALSE, echo = FALSE}
library(knitr)
knitr::opts_chunk$set(comment = "")
```


```{r, warning=FALSE, message=FALSE}
library(topicdict)
library(quanteda)
```

We'll use the Bara data, and seeds extracted from the dictionary.  
These are all in package `extdata`:
```{r}
doc_folder <- system.file(file.path("extdata", "bara_paras"), package = "topicdict")
seed_file <- system.file(file.path("extdata", "bara_seeds.txt"), package = "topicdict")

## turn this flat file of seeds into a (quanteda dictionary) list as it would be used
seed_list <- Map(function(x){ unlist(strsplit(x, " ")) }, 
                 Filter(function(x){ !grepl(x, pattern = "#") }, # remove comments
                        readLines(seed_file)))

# Original topic names from Bara dictionary
names(seed_list) <- c("advocacy", "legal", "medical", "moral", "procedural", "social")
dict <- dictionary(seed_list)
dict
```

Initialize a model with the default tokenization options, without removing
stopwords or stemming
```{r}
set.seed(12345)

stops <- setdiff(c(stopwords("english"), letters), 
                  c("he", "his", "him", "himself", "she", "hers", "her", "herself"))
model <- topicdict_model(file.path(doc_folder, "*.txt"), dict, stopwords = stops)
```
And run three models:
```{r}
model <- topicdict_train(model, iter = 60)
```

Now let's bundle up the posterior and use the new functions on it
```{r}
post <- posterior(model)
top_terms(post, show_seed = TRUE) 
```
