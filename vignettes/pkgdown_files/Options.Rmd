---
title: "Options"
output: 
  html_document:
    toc: false
pkgdown:
  as_is: true
---

`keyATM_fit()` takes various options.



## `seed`
This is a seed used to generate random numbers. The same seed is used for initialization and fitting the model (`set.seed()` is executed before both initialization and fitting). If you do not provide `seed`, **keyATM** randomly selects a seed for you.

## `output_per`


## `iterations`
The  default value is `1500`.


## `use_weights`
The default value is `1` (use weights). We follow the weighting Scheme in Wilson \& Chew (2010). It uses an axiom of information theory: an event $a$'s information content: $- \log_2 p(a)$. We assume that information content of a term $v$ follows this metric. The weight for a word $v$ is,

$$
\begin{align*}
    m(v) &= -\log_2 \dfrac{\text{# of word $v$ in corpus}}{\text{# of total occurrence}}\\
    & = -\log_2 \frac{\sum_{d=1}^D \sum_{i=1}^{n_d} 1 \{w_{di} = v \} }{\sum_{d=1}^D \sum_{i=1}^{n_d} 1 }.
\end{align*}
$$

This changes the sampling formula. Sampling topic with weights ($x_{di} =v$) would be
$$
\begin{align*}
        p(z_{di}=k) = \frac{m(v) N_{dk}^{-di} + \beta }{\sum_v m(v) N_{dk}^{-di} + \beta} \cdot \frac{m(v) N_{vk}^{-di} + \alpha }{\sum_v m(v) N_{vj}^{-di} + \alpha}.
\end{align*}
$$

If you do not want to use weights, please set it to `0`.


## `thinning`


## `store_theta`


## `slice_shape`


