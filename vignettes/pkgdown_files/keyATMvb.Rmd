---
title: "keyATM with Collapsed Variational Bayes"
output: 
  html_document:
    toc: true
---


```{r setup II, include=FALSE, eval=TRUE}
knitr::opts_chunk$set(eval = T, echo = TRUE)
```

# Before you start
 `keyATMvb` is an experimental function. Codes and derivations may contain errors. Please leave feedback in [GitHub Issues](https://github.com/keyATM/keyATM/issues).

# Usage

```{r, eval=FALSE}
library(keyATM)
data(keyATM_data_bills)
bills_dfm <- keyATM_data_bills$doc_dfm
bills_keywords <- keyATM_data_bills$keywords
keyATM_docs <- keyATM_read(bills_dfm)

out <- keyATMvb(docs = keyATM_docs,
                no_keyword_topics = 3,
                keywords = bills_keywords,
                model = "base",
                options = list(seed = 250),
                vb_options = list(convtol = 1e-4, init = "mcmc"))
```

\newcommand{\Beta}{\textsf{Beta}}
\newcommand{\Binomial}{\text{Binomial}}
\newcommand{\Bern}{\textsf{Bernoulli}}
\newcommand{\Expo}{\textsf{Expo}}
\newcommand{\Pois}{\textsf{Pois}}
\newcommand{\Unif}{\textsf{Uniform}}
\newcommand{\Normal}{\textsf{Normal}}
\newcommand{\Gammad}{\textsf{Gamma}}
\newcommand{\logit}{\text{logit}}
\newcommand{\expit}{\text{expit}}
\newcommand{\mexpit}{\text{mexpit}}
\newcommand{\Dir}{\textsf{Dirichlet}}
\newcommand{\Multi}{\textsf{Multi}}
\newcommand{\Cat}{\textsf{Categorical}}

\newcommand{\pr}{\text{pr}}
\newcommand{\var}{\text{var}}
\newcommand{\cov}{\text{cov}}
\newcommand{\sumN}{\sum_{i=1}^N}
\newcommand{\wt}{\tilde}

\newcommand{\E}{\mathbb{E}}
\newcommand{\Eq}{\mathbb{E}_q}
\newcommand{\bX}{\mathbf{X}}
\newcommand{\bx}{\mathbf{x}}
\newcommand{\bs}{\mathbf{s}}
\newcommand{\bc}{\mathbf{c}}
\newcommand{\bI}{\mathbf{I}}
\newcommand{\bM}{\mathbf{M}}
\newcommand{\bP}{\mathbf{P}}
\newcommand{\bQ}{\mathbf{Q}}
\newcommand{\bV}{\mathbf{V}}
\newcommand{\bU}{\mathbf{U}}
\newcommand{\bW}{\mathbf{W}}
\newcommand{\bw}{\mathbf{w}}
\newcommand{\ATE}{\textsf{ATE}}
\newcommand{\bepsilon}{\bm{\epsilon}}
\newcommand{\boldeta}{\bm{\eta}}

\newcommand{\bA}{\bm{A}}
\newcommand{\ba}{\bm{a}}
\newcommand{\bh}{\bm{h}}
\newcommand{\bZ}{\bm{Z}}
\newcommand{\bz}{\mathbf{z}}
\newcommand{\bD}{\bm{D}}
\newcommand{\bd}{\bm{d}}
\newcommand{\be}{\vec{\mathbf{e}}}
\newcommand{\bY}{\bm{Y}}
\newcommand{\cI}{\mathcal{I}}
\newcommand{\cL}{\mathcal{L}}
\newcommand{\cW}{\mathcal{W}}
\newcommand{\cQ}{\mathcal{Q}}
\newcommand{\cV}{\mathcal{V}}
\newcommand{\cZ}{\mathcal{Z}}
\newcommand{\cD}{\mathcal{D}}
\newcommand{\oD}{\overline{D}}
\newcommand{\oY}{\overline{Y}}
\newcommand{\bone}{\mathbf{1}}
\newcommand{\I}{\unicode{x1D7D9}}
\newcommand{\Iz}{\unicode{x1D7D9}(z_{di} = k)}

\newcommand{\zdi}{z_{di}}
\newcommand{\wdi}{w_{di}}
\newcommand{\wdinew}{w_{di}^{*} = v}
\newcommand{\wdiv}{w_{di} = v}
\newcommand{\zdik}{z_{di} = k}
\newcommand{\bzremove}{\bz^{-di}}
\newcommand{\bwremove}{\bw^{-di}}
\newcommand{\bsremove}{\bs^{-di}}
\newcommand{\sdione}{s_{di} = 1}
\newcommand{\sdizero}{s_{di} = 0}
\newcommand{\sdis}{s_{di} = s}
\newcommand{\sdi}{s_{di}}
\newcommand{\bthetad}{\btheta_{d}}
\newcommand{\balphad}{\balpha_{d}}
\newcommand{\alphadk}{\alpha_{dk}}

\newcommand{\sumd}{\sum_{d=1}^{D}}
\newcommand{\sumi}{\sum_{i=1}^{Nd}}
\newcommand{\sumk}{\sum_{k=1}^{K}}
\newcommand{\sums}{\sum_{s=0}^{1}}
\newcommand{\sumv}{\sum_{v=1}^{V}}

\newcommand{\prodd}{\prod_{d=1}^{D}}
\newcommand{\prodi}{\prod_{i=1}^{Nd}}
\newcommand{\prodk}{\prod_{k=1}^{K}}
\newcommand{\prodv}{\prod_{v=1}^{V}}
\newcommand{\prods}{\prod_{s=0}^{1}}


\newcommand{\btheta}{\boldsymbol{\theta}}
\newcommand{\bbeta}{\boldsymbol{\beta}}
\newcommand{\balpha}{\boldsymbol{\alpha}}
\newcommand{\bsigma}{\boldsymbol{\sigma}}
\newcommand{\bgamma}{\boldsymbol{\gamma}}
\newcommand{\blambda}{\boldsymbol{\lambda}}
\newcommand{\bphi}{\boldsymbol{\phi}}
\newcommand{\bpsi}{\boldsymbol{\psi}}
\newcommand{\bpi}{\boldsymbol{\pi}}

\newcommand{\KIRT}{\textsf{KIRT}}
\newcommand{\keyATMCov}{\textsf{covariate keyATM}}
\newcommand{\keyATMDynamic}{\textsf{dynamic keyATM}}
\newcommand{\LDA}{\textsf{LDA}}
\newcommand{\STM}{\textsf{STM}}
\newcommand{\kprime}{k^{'}}
\newcommand{\vprime}{v^{'}}
\newcommand{\zdel}{\mathbf{z}^{- mti}}


# Derivation

## Evidence Lower Bound
\begin{align}
 & \log p(\bw \mid \balpha, \bbeta, \bgamma, \wt{\bbeta}) \\
 &= \log \sum_{z,s} p(\bw, \bz, \bs \mid \balpha, \bbeta, \wt{\bbeta}, \bgamma) \\
 &= \log \sum q(\bz, \bs) \frac{p(\bw, \bz, \bs \mid \balpha, \bbeta, \wt{\bbeta}, \bgamma)}{q(\bz, \bs)}\\
 &\geq \sum q(\bz, \bs) \log \frac{p(\bw, \bz, \bs \mid \balpha, \bbeta, \wt{\bbeta}, \bgamma)}{q(\bz, \bs)}\\
 &= \Eq [\log p(\bw, \bz, \bs \mid \balpha, \bbeta, \bgamma)] - \Eq [\log q(\bz)] - \Eq[q(\bs)] \label{eq:ELBO}
 % &= \sum q(\bz) q(\bs) \log \frac{p(\bw \mid \bz, \bs, \bbeta, \wt{\bbeta}) p(\bz \mid \balpha) p(\bs \mid \bgamma)}{q(\bz) q(\bs)} \\
 % &= \Eq[\log p(\bw \mid \bz, \bs, \bbeta, \wt{\bbeta})] + \Eq[\log p(\bz \mid \balpha)] + \Eq[\log p(\bs \mid \bgamma)] - \Eq[q(\bz)] - \Eq[q(\bs)]
\end{align}
where we use Jensen's inequality and factorization assumption.




## Update parameters

### Update $q(\bz)$
Extract terms related $q(\zdi)$ from ELBO.
\begin{align}
  \cL[q(\zdi)] &= \sum_{\bz} q(\zdi) q(\bzremove) q(\sdi) q(\bsremove) \log \frac{p(\wdi, \zdi, \sdi \mid \bwremove, \bzremove, \bsremove, \balpha, \bbeta, \bgamma)}{q(\zdi)}
\end{align}

We combine the results of Variational Bayes and Collapsed Gibbs Sampling. From Variational Bayes,
\begin{align}
  &q(\zdik) \propto \exp \bigg( \int q(\sdione) q(\wt{\phi}_{kv})  \log \wt{\phi}_{kv}\   d\wt{\phi}_{kv} + \int q(\sdizero) q({\phi}_{kv})  \log {\phi}_{kv}\   d{\phi}_{kv}   \bigg) \\
  &\quad \times \exp \bigg( \int q(\theta_{dk}) \log \theta_{dk}\ d\theta_{dk}  \bigg) 
  \times \exp \bigg(  q(\sdione) \int q(\pi_k)\log \pi_k\ d\pi_k   \bigg) \times \exp \bigg( \int q(\pi_k)\log \pi_k\ d\pi_k  \bigg) \\
  %%%%%%%%
  &= \exp \bigg( q(\sdione) \int q(\wt{\phi}_{kv})  \log \wt{\phi}_{kv}\   d\wt{\phi}_{kv} + q(\sdione) \int q(\pi_k)\log \pi_k\ d\pi_k    \bigg) \\
  &\quad \times \exp \bigg( q(\sdizero) \int  q({\phi}_{kv})  \log {\phi}_{kv}\   d{\phi}_{kv} + q(\sdizero) \int q(\pi_k)\log \pi_k\ d\pi_k     \bigg) \times \exp \bigg( \int q(\theta_{dk}) \log \theta_{dk}\ d\theta_{dk}  \bigg)
  %%%%%%%%
\end{align}
%
Results of Collapsed Gibbs Sampling show,
\begin{align}
  &\quad \Pr(z_{di}=k \mid \bzremove, \bw, \bs, \balpha, \bbeta,
    \wt{\bbeta}, \bgamma) 
\propto 
\begin{cases} %
  \frac{\displaystyle \beta_v + n_{k v}^{- di} }{\displaystyle   V \beta_v +  n_{k}^{- di}} \cdot %
  \frac{\displaystyle n^{- di}_{k} + \gamma_1 }{\displaystyle \tilde{n}_{k}^{- di} + \gamma_1 + n^{- di}_{k} + \gamma_2 } \cdot %
\left(n_{d{k}}^{- di} + \alpha_{dk}  \right)  & \ {\rm if \ } s_{di} = 0, \\ 
\frac{\displaystyle \tilde{\beta}_v + \tilde{n}_{k v}^{- di}    }{\displaystyle  L_{k} \tilde{\beta}_v + \tilde{n}_{k }^{- di}  } \cdot%
\frac{\displaystyle \tilde{n}^{ - di}_{k} + \gamma_2 }{\displaystyle \tilde{n}^{- di}_{k} + \gamma_1 + n^{- di}_{k} + \gamma_2 } \cdot %
\left(n_{d{k}}^{- di} + \alpha_{dk}  \right) & \ {\rm if \ } s_{di} = 1.
\end{cases}\label{eq:sample-z-base}
\end{align}
%
We replace some of the integrations with the results of the Collapsed Gibbs Sampling,
\begin{align}
  q(\zdik) &\propto \exp \bigg( q(\sdizero) \bigg( \Eq \bigg[ \log \frac{\displaystyle \beta_v + n_{k v}^{- di} }{\displaystyle   V \beta_v +  n_{k}^{- di}} \bigg] +  \Eq \bigg[\log  \frac{\displaystyle n^{- di}_{k} + \gamma_1 }{\displaystyle \tilde{n}_{k}^{- di} + \gamma_1 + n^{- di}_{k} + \gamma_2 } \bigg]  \bigg)   \bigg) \\
  &\quad \times \exp \bigg( q(\sdione) \bigg( \Eq \bigg[ \log \frac{\displaystyle \tilde{\beta}_v + \tilde{n}_{k v}^{- di}    }{\displaystyle  L_{k} \tilde{\beta}_v + \tilde{n}_{k v}^{- di}  } \bigg] +  \Eq \bigg[ \log \frac{\displaystyle \tilde{n}^{ - di}_{k} + \gamma_2 }{\displaystyle \tilde{n}^{- di}_{k} + \gamma_1 + n^{- di}_{k} + \gamma_2 }  \bigg]   \bigg)  \bigg) \\
  &\quad \times \exp \bigg( \Eq \big[ \log ( n_{d{k}}^{- di} + \alpha_{k} ) \big]  \bigg) \\
%%%%%%%%%%%%%%%%%%%
  &=  \frac{\exp \big[ q(\sdizero)  \Eq[\log (\beta_v + n_{k v}^{- di}) ] \big] }{\exp \big[ q(\sdizero) \Eq[\log ( V \beta_v +  n_{k}^{- di} )] \big]} \times \frac{\exp \big[ q(\sdizero) \Eq[\log (n^{- di}_{k} + \gamma_1)] \big]}{ \exp \big[ q(\sdizero) \Eq[\log (\tilde{n}_{k}^{- di} + \gamma_1 + n^{- di}_{k} + \gamma_2)] \big]}     \\
  &\quad \times \frac{\exp \big[ q(\sdione)  \Eq[\log (\tilde{\beta}_v + \tilde{n}_{k v}^{- di})] \big]}{ \exp \big[ q(\sdione) \Eq[\log (L_{k} \tilde{\beta}_v + \tilde{n}_{k v}^{- di})] \big]} \times \frac{ \exp \big[ q(\sdione) \Eq[\log (\tilde{n}^{ - di}_{k} + \gamma_2)] \big]} {\exp \big[ q(\sdione) \Eq[\log (\tilde{n}^{- di}_{k} + \gamma_1 + n^{- di}_{k} + \gamma_2)] \big]}   \\
  &\quad \times \exp \bigg( \Eq \big[ \log ( n_{d{k}}^{- di} + \alpha_{k} ) \big] \bigg)
\end{align}

Note that
\begin{align}
  \exp \bigg(c \log \frac{a}{b} \bigg) = \exp (c\log a - c\log b) = \frac{\exp(c \log a)}{\exp(c \log b)}.
\end{align}

Next, we approximate expectations. We use Taylor expansion around $a$,
\begin{align}
  \log x \approx \log a + \frac{1}{a} (x-a).
\end{align}
If $a = \E[x]$,
\begin{align}
  \E [\log x] &\approx \E \bigg[ \log \E[x] + \frac{1}{\E[x]} (x - \E[x]) \bigg]
  = \log \E[x] + \frac{1}{\E[x]} (\E[x] - \E[x]) 
  = \log \E[x],
\end{align}
which is called CVB0. For example
\begin{align}
  \E_{q}[\log ( \beta_v + n_{k v}^{- di})  ] &= \log \E_{q}[\beta_v + n_{k v}^{- di}] 
  = \log ( \beta_v + \E_{q}[n_{k v}^{- di}] ).
\end{align}

Hence,
\begin{align}
 & q(\zdik) \propto \frac{\exp \big[ q(\sdizero) \log (\E_{q}[n_{k v}^{- di} ] + \beta_v)  \big] }{\exp \big[ q(\sdizero) \log(\E_{q} [ n_{k}^{- di} ] + V \beta_v) \big]} \times \frac{\exp\big[ q(\sdizero) \log(\E_{q} [n^{- di}_{k} ] + \gamma_1)  \big]}{\exp \big[ q(\sdizero) \log(\E_{q} [ \tilde{n}_{k}^{- di} + n^{- di}_{k}] + \gamma_1 + \gamma_2) \big]}     \\
  &\quad \times \frac{\exp \big[ q(\sdione) \log (\E_{q}[ \tilde{n}_{k v}^{- di} ] + \tilde{\beta}_v)   \big]}{ \exp \big[ q(\sdione) \log (\E_{q}[  \tilde{n}_{k}^{- di} ] +  L_{k} \tilde{\beta}_v) \big]} 
  \times \frac{ \exp \big[ q(\sdione)\log(\E_{q}[ \tilde{n}^{ - di}_{k} ] + \gamma_2)] \big]} {\exp \big[ q(\sdione) \log (\E_{q}[ \tilde{n}^{- di}_{k}  + n^{- di}_{k}  ] + \gamma_1 + \gamma_2) \big]}   \\
  &\quad \times \big( \E_{q} [n_{d{k}}^{- di}  ]  + \alpha_{dk} \big) \\
%%%%%%%%%%%%%%%%
  &= \exp \bigg[ q(\sdizero) \bigg( \log (\E_{q}[n_{k v}^{- di} ] + \beta_v) - \log(\E_{q} [ n_{k}^{- di} ] + V \beta_v) + \log(\E_{q} [n^{- di}_{k} ] + \gamma_1)  - \log(\E_{q} [ \tilde{n}_{k}^{- di} + n^{- di}_{k}] + \gamma_1 + \gamma_2) \bigg) \\
  &\quad +  q(\sdione) \bigg( \log (\E_{q}[ \tilde{n}_{k v}^{- di} ] + \tilde{\beta}_v) - \log (\E_{q}[  \tilde{n}_{k}^{- di} ] +  L_{k} \tilde{\beta}_v) + \log(\E_{q}[ \tilde{n}^{ - di}_{k} ] + \gamma_2) - \log (\E_{q}[ \tilde{n}^{- di}_{k}  + n^{- di}_{k}  ] + \gamma_1 + \gamma_2) \bigg) \bigg]  \\
  &\quad \times \big( \E_{q} [n_{d{k}}^{- di}  ]  + \alpha_{dk} \big)
\end{align} 
where
\begin{align}
  %%%%%%%%%%%%
  \E_{q(\bzremove) q(\bs)}[n_{k v}^{- di}] &= \E_{q(\bzremove) q(\bs)} \bigg[\sumd \sum_{i'\neq i}^{N_d} \I(z_{di'} = k) \I(s_{di'} = 0) \I(w_{di'} = v) \bigg]  \\
  &= \sumd \sum_{i'\neq i}^{N_d} \E_{q(\bzremove)}[\I(z_{di'} = k)] \E_{q(\bs)}[\I(s_{di'} = 0)] \I(w_{di'} = v)\\
  &= \sumd \sum_{i'\neq i}^{N_d} q(z_{di'} = k) q(s_{di'} = 0) \I(w_{di'} = v) \\
  %%%%%%%%%%%%
  \E_{q(\bzremove) q(\bs)}[\tilde{n}_{k v}^{- di}] &= \E_{q(\bzremove) q(\bs)} \bigg[\sumd \sum_{i\neq i'}^{N_d} \I(z_{di'} = k) \I(s_{di'} = 1) \I(w_{di'} = v) \bigg]  \\
  &= \sumd \sum_{i'\neq i}^{N_d} \E_{q(\bzremove)}[\I(z_{di'} = k)] \E_{q(\bs)}[\I(s_{di'} = 1)] \I(w_{di'} = v)\\
  &= \sumd \sum_{i'\neq i}^{N_d} q(z_{di'} = k) q(s_{di'} = 1) \I(w_{di'} = v)\\
  %%%%%%%%%%%%
  \E_{q(\bzremove) q(\bs)}[{n}_{k}^{- di}] &=  \E_{q(\bzremove) q(\bs)} \bigg[\sumd \sum_{i' \neq i}^{N_d} \I(z_{di'} = k) \I(s_{di'} = 0) \bigg] \\
  &= \sumd \sum_{i'\neq i}^{N_d} q(z_{di'} = k) q(s_{di'} = 0) \\
  %%%%%%%%%%%%
  \E_{q(\bzremove) q(\bs)}[\tilde{n}_{k}^{- di}] &=  \E_{q(\bzremove) q(\bs)} \bigg[\sumd \sum_{i' \neq i}^{N_d} \I(z_{di'} = k) \I(s_{di'} = 1) \bigg] \\
  &= \sumd \sum_{i'\neq i}^{N_d} q(z_{di'} = k) q(s_{di'} = 1) \\
  %%%%%%%%%%%%
  \E_{q(\bzremove) q(\bs)} [n_{d{k}}^{- di}] &= \E_{q(\bzremove) q(\bs)} \bigg[ \sum_{i' \neq i}^{N_d}  \I(z_{di'} = k)  \bigg] \\
  &= \sum_{i' \neq i}^{N_d} q(z_{di'} = k) 
  %%%%%%%%%%%%
  % \E_{q(\bzremove) q(\bs)} [\tilde{n}_{d{k}}^{- di}] &= \E_{q(\bzremove) q(\bs)} \bigg[ \sum_{i' \neq i}^{N_d}  \I(z_{di'} = k) \I(s_{di'} = 1) \bigg] \\
  % &= \sum_{i' \neq i}^{N_d} q(z_{di'} = k) q(s_{di'} = 1)
\end{align}




### Update $q(\bs)$
Extract terms related to $q(\sdi)$ from ELBO.
\begin{align}
  \cL[q(\sdi)] &= \sum_{\bz} q(\zdi) q(\bzremove) q(\sdi) q(\bsremove) \log \frac{p(\wdi, \zdi, \sdi \mid \bzremove, \bsremove, \bgamma)}{q(\sdi)}
\end{align}


Results of the Collapsed Gibbs Sampling show,
\begin{align}
  \Pr(s_{di}  = s \mid \bs^{- di}, \bz, \bw,  \bbeta,  \wt{\bbeta}, \bgamma)
  & \ \propto \
\begin{cases}  
	\frac{\displaystyle \beta_v + n_{z_{di}, v}^{- di}    }{ \displaystyle V \beta_v + n_{z_{di}}^{ - di} } \cdot %
  (\displaystyle n^{- di}_{z_{di}} + \gamma_1 )  %
	& {\rm if} \quad s  = 0, \\ 
  \frac{\displaystyle \tilde{\beta}_v + \tilde{n}_{z_{di}, v}^{- di}    }{\displaystyle  L_{z_{di}}  \tilde{\beta}_v + \tilde{n}_{z_{di}}^{- di}  } \cdot%
  (\displaystyle \tilde{n}^{- di}_{z_{di}} + \gamma_2 ) %
	&  {\rm if} \quad  s = 1.
\end{cases}
\end{align}

From the Variational Bayes,
\begin{align}
q(\sdizero) &\propto \exp \bigg( \sumk q(\zdik) \bigg[ \int q({\phi}_{k, w_{di}}) \log {\phi}_{k, w_{di}}\ d{\phi}_{k, w_{di}} + \int q(\pi_k) \log \pi_k \ d\pi_k \bigg] \bigg) \\
  q(\sdione) &\propto \exp \bigg( \sumk q(\zdik) \bigg[ \int q(\wt{\phi}_{k, w_{di}}) \log \wt{\phi}_{k, w_{di}}\ d\wt{\phi}_{k, w_{di}} +  \int q(\pi_k) \log \pi_k \ d\pi_k \bigg] \bigg)
\end{align}


We replace the some parameters with the results of the Collapsed Gibbs Sampling and the approximate the expectations,
\begin{align*}
  q(\sdizero) &\propto \exp \bigg[ \sumk q(\zdik) \bigg( \log (\E_{q(\bz) q(\bsremove)}[ n_{k v}^{- di} ]+ \beta_v) - \log (\E_{q(\bz) q(\bsremove)}[ n_{k}^{ - di} ] + V \beta_v) + \log ( \E_{q(\bz) q(\bsremove)}[ n^{- di}_{k}] + \gamma_1 ) \bigg) \bigg] \\
%%%%%%%%%%%%%%%%%%
  q(\sdione) &\propto \exp \bigg[ \sumk q(\zdik) \bigg( \log (\E_{q(\bz) q(\bsremove)}[ \tilde{n}_{k v}^{- di} ]+ \wt{\beta}_v) - \log (\E_{q(\bz) q(\bsremove)}[ \tilde{n}_{k}^{ - di} ] + L_k \wt{\beta}_v) + \log ( \E_{q(\bz) q(\bsremove)}[ \tilde{n}^{- di}_{k}] + \gamma_2) \bigg) \bigg]
\end{align*}

## Calculating perplexity
We cannot calculate the log-likelihood explicityly, so we check the approximated perplexity instead.
\begin{align*}
  &p(\wdinew \mid \bw, \balpha, \bbeta, \wt{\bbeta}, \bgamma) \\
  &= \sum_{\bz, \bs} \int p(\wdinew, \bz, \bs, \btheta, \bphi, \wt{\bphi}, \bpi \mid \bw, \balpha, \bbeta, \wt{\bbeta}, \bgamma) d\bphi d\wt{\bphi} d\btheta d\bpi \\
  &\approx \sum_{\bz, \bs} \int p(\wdinew, \bz, \bs \mid \btheta, \bphi, \wt{\bphi}, \bpi) q(\btheta, \bphi, \wt{\bphi}, \bpi) d\bphi d\wt{\bphi} d\btheta d\bpi \\
%%%%%%%%%%%%%%%%%%%%
  &\approx \sumk \int p(\wdinew, \zdik \mid \btheta, \bphi, \sdizero) q(\sdizero \mid \bpi) q(\btheta) q(\bphi) d\bphi d\btheta d\bpi \\
  &\quad\quad + \sumk \int p(\wdinew, \zdik \mid \btheta, \wt{\bphi}, \sdione) q(\sdione \mid \bpi) q(\btheta) q(\wt{\bphi}) d\wt{\bphi} d\btheta d\bpi\\
%%%%%%%%%%%%%%%%%%%%
  &=  \sumk \int q(\bphi_{k}) \phi_{kv} d\phi_{k} \int  q(\theta_{d}) \theta_{dk} d\theta_{d} \int q(\sdizero \mid \pi_k) \pi_k  d\pi_k +
  \sumk  \int q(\wt{\bphi}_{k}) \wt{\bphi}_{kv} d\wt{\bphi}_{k} \int  q(\theta_{d}) \theta_{dk} d\theta_{d} \int q(\sdione \mid \pi_k) \pi_k  d\pi_k \\
%%%%%%%%%%%%%%%%%%%%
&= \sumk \bigg[ 
  \frac{\displaystyle  \E_{q}[n_{k v} ] + \beta_v  }{\displaystyle \E_{q} [ n_{k} ] + V \beta_v} \cdot \dfrac{\E_{q} [n_{d{k}}  ]  + \alpha_{dk}}{ n_d + \sum_{k'=1}^K \alpha_{dk}} \cdot \frac{\displaystyle \E_q[n_k] + \gamma_2 }{\displaystyle \E_q[\tilde{n}_k] + \gamma_1 + \E_q[n_k] + \gamma_2 } 
 +  
 \frac{\displaystyle  \E_{q}[\tilde{n}_{k v} ] + \beta_v  }{\displaystyle \E_{q} [ \tilde{n}_{k} ] + L_k \beta_v} \cdot \dfrac{\E_{q} [{n}_{d{k}}  ]  + \alpha_{dk}}{ {n}_d + \sum_{k'=1}^K \alpha_{dk}} \cdot \frac{\displaystyle \E_q[\tilde{n}_k] + \gamma_1 }{\displaystyle \E_q[\tilde{n}_k] + \gamma_1 + \E_q[n_k] + \gamma_2 }  \bigg]
\end{align*}
